{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Necesitaras tener instaladas estas dos librerías que definen los modelos de machine learning que vamos a optimizar con un algoritmo genético.\n",
    "!pip install xgboost\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica 3. Optimización de modelos de aprendizaje automático con algoritmos genéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando ajustamos un modelo de machine learning, los hiperparámetros (como la profundidad máxima de un árbol, la tasa de aprendizaje, el número de estimadores, etc.) juegan un papel crucial en el rendimiento del modelo. \n",
    "Seleccionar buenos valores para estos hiperparámetros es importante para mejorar la precisión del modelo y evitar el sobreajuste.\n",
    "En esta práctica vamos a elegir los parámetros que optimizan la precisión del modelo usando un algoritmo genético. \n",
    "\n",
    "Vamos a utilizar la librería Scikit-learn (o sklearn), una biblioteca de machine learning para Python que proporciona herramientas simples y eficientes para el análisis y modelado de datos. Es ampliamente utilizada en la comunidad de ciencia de datos y aprendizaje automático debido a su facilidad de uso y la robustez de sus algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imprt numpy as np\n",
    "imoport pandas as pd\n",
    "from sklearn.datasets import load_wine, fetch_california_housing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "from itertools import product\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datasets\n",
    "Puedes elegir cualquiera de los datasets de prueba que vienen con la librería sklearn \n",
    "https://scikit-learn.org/1.5/datasets/toy_dataset.html\n",
    "A continuación tienes algunos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset wine que viene como ejemplo en sklearn: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
    "dataset = load_wine()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset de precios de casas que viene como ejemplo en sklearn (se binariza el target): \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing\n",
    "dataset = fetch_california_housing()\n",
    "dataset.target = np.where(dataset.target > np.median(dataset.target), 1, 0)\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien puedes utilizar tu propio archivo de datos en formato csv. En este ejemplo vamos a usar el dataset  titanic.csv que te puedes descargar de Kaggle (también lo puedes descargar del campus virtual).\n",
    "Después los dividimos en dos partes, conjunto de entrenamiento y conjunto de prueba (para evaluar el modelo entrenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset de Titanic, que se puede descargar de Kaggle:\n",
    "#https://www.kaggle.com/c/titanic/data\n",
    "dataset = pd.read_csv('titanic.csv')\n",
    "X = dataset[dataset.columns[:-1]]\n",
    "y = dataset[dataset.columns[-1:]]\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos que vamos a optimizar \n",
    "\n",
    "Puedes elegir cualquier de los dos modelos siguientes para optimizar: modelo con XGBoost o modelo con perceptron multicapa. Aprenderás más de los modelos de machine learning en otras asignaturas. Para esta práctica los modelos funcionan como cajas negras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost es una biblioteca optimizada y eficiente de machine learning basada en el algoritmo de Gradient Boosting. Su nombre es un acrónimo de \"Extreme Gradient Boosting\". XGBoost es conocido por su alto rendimiento y velocidad.\n",
    "XGBoost se basa en el principio de Gradient Boosting, donde se construyen modelos secuencialmente, y cada nuevo modelo trata de corregir los errores cometidos por el modelo anterior. Específicamente en cada iteración, se ajusta un modelo débil (usualmente un árbol de decisión) a los residuos (errores) de los modelos anteriores. El objetivo es minimizar una función de pérdida usando el gradiente descendente, lo que le permite mejorar iterativamente la precisión del modelo.\n",
    "\n",
    "En esta práctica vamos a elegir los valores de los parámetros que optimizan la precisión del modelo usando un algoritmo genético. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_space = {\n",
    "    \"gamma\": np.arange(0, 0.5, 0.1),\n",
    "    \"learning_rate\": np.array([0.01, 0.1, 0.2, 0.3, 0.4]),\n",
    "    \"max_depth\": np.arange(3, 10, 1), \n",
    "    \"n_estimators\": np.arange(50, 750, 50), \n",
    "    \"subsample\": np.arange(0.4, 1.0, 0.1),\n",
    "    \"min_child_weight\" : np.arange(0, 10, 1),\n",
    "    \"subsample\": np.arange(0.4, 1.0, 0.1),\n",
    "    \"colsample_bytree\": np.arange(0.4, 1.0, 0.1),\n",
    "    \"scale_pos_weight\": np.arange(0, 50, 10),\n",
    "}\n",
    "\n",
    "# ParameterGrid crea un iterable de todas las combinaciones posibles de hiperparámetros dados en forma de diccionario.\n",
    "# ParameterGrid se usa a menudo dentro de GridSearchCV\n",
    "\n",
    "search_space = list(ParameterGrid(hyperparameter_space))\n",
    "print('Combinations: ', len(search_space))\n",
    "\n",
    "# Creamos el modelo. Todavía no está entrenado\n",
    "xgb_model = xgb.XGBClassifier( n_jobs=-1, random_state=42)\n",
    "model = xgb_model\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto sería un ejemplo de cómo crear un modelo XGBClassifier con algunos hiperparámetros personalizados\n",
    "¿Cómo sabemos cuáles son los mejores valores? \n",
    "Se prueban y se evaluan modelos con distintas configuraciones de hiperparámetros. Hay 4410000 combinaciones para elegir. \n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        gamma=0,\n",
    "        reg_alpha=0.01,\n",
    "        reg_lambda=1,\n",
    "        scale_pos_weight=1,\n",
    "        objective='binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con Perceptron Multicapa\n",
    "Este modelo es considerablemente más lento que XGBoost porque no está paralelizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_neurons = np.arange(10, 100, 10)\n",
    "second_layer_neurons = np.arange(10, 100, 10)\n",
    "hidden_layer_sizes = list(product(first_layer_neurons, second_layer_neurons))\n",
    "\n",
    "hyperparameter_space = {\n",
    "    \"hidden_layer_sizes\": hidden_layer_sizes,\n",
    "    \"activation\": ['logistic', 'tanh', 'relu'],\n",
    "    \"solver\": ['sgd', 'adam', 'lbfgs'],\n",
    "    \"alpha\": 10.0 ** -np.arange(1, 10),\n",
    "    \"learning_rate\": ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "\n",
    "search_space = list(ParameterGrid(hyperparameter_space))\n",
    "print('Combinations: ', len(search_space))\n",
    "\n",
    "# MLP is more \"delicate\" than XGBoost, so we need to preprocess the data removing NaNs and scaling it\n",
    "imp = SimpleImputer( strategy='mean')\n",
    "X = imp.fit_transform(X)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "mlp_model = MLPClassifier(max_iter = 1000, random_state=42)\n",
    "model = mlp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busqueda de los mejores hiperparametros utilizando los métodos de scikit-learn\n",
    "\n",
    "La librería Scikit-learn ofrece sus propios métodos de optimización de hiperparámetros, por ejemplo, recorrer exhaustivamente todas las combinaciones posibles (GridSearchCV), o usar RandomizedSearchCV que explora un número aleatorio de combinaciones de hiperparámetros. RandomizedSearchCV selecciona aleatoriamente un número especificado de combinaciones y evalúa el rendimiento del modelo para cada una de ellas. Esto reduce significativamente el tiempo de búsqueda, haciendo posible encontrar buenos (aunque no necesariamente óptimos) conjuntos de hiperparámetros con mayor rapidez. \n",
    "Aun así puedes comprobar que tarda bastante. Horas (dependiendo del dataset y del modelo). GridSearch es todavía más ineficiente.  Según el tamaño del espacio de hiperparámetros estas opciones no son aplicables. Vamos a ver si podemos mejorarlo con un algoritmo genético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "search = RandomizedSearchCV(model, param_distributions=hyperparameter_space, random_state=42, n_iter=200, cv=5, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Time: %s seconds \" % (time.time() - start_time))\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "search = GridSearchCV(model, param_grid=hyperparameter_space, cv=5, verbose=2, n_jobs=-1, return_train_score=True)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Time: %s seconds \" % (time.time() - start_time))\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsqueda exhaustiva manual de los mejores hiperparámetros\n",
    "Otra opción es programar una busqueda exhaustiva manual o probar aleatoriamente un subconjunto de las opciones. Pero, igual que las opciones anteriores, no son opciones muy útiles. \n",
    "    1: Búsqueda greedy: tarda varios días en ejecutarse (con suerte)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# tqdm es un wrapper para objetos iterativos que muestra una barra de progreso mientras se ejecuta el bucle.\n",
    "for params in tqdm(search_space): #tqdm shows progress bar\n",
    "    # Set the model parameters\n",
    "    model.set_params(**params)\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Evaluate the model comparing the predictions with the actual values\n",
    "    score = accuracy_score(y_test, y_pred)    \n",
    "    #print(score, params) #  descomentar para ver los resultados parciales, el score conseguido con una cierta combinación de parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2: búsqueda random: tarda unas horas en ejecutarse dependiendo del dataset pero los resultados no son buenos en general."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "percentage = .05 # Sólo va a a explorar un porcentaje de 5% del espacio de búsqueda\n",
    "random_space = random.sample(search_space, k=round(len(search_space) * percentage))\n",
    "\n",
    "for params in tqdm(random_space):\n",
    "    # Set the model parameters\n",
    "    model.set_params(**params)\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Evaluate the model comparing the predictions with the actual values\n",
    "    score = accuracy_score(y_test, y_pred)    \n",
    "    #print(score, params) #Descomentar para ver los resultados parciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo genético "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pide resolver el problema de optimizar los hiperparámetros de alguno de los modelos propuestos usando un algoritmo genético. \n",
    "Puedes implementar tus propias variaciones de las funciones de selección, cruce y mutación o utilizar las que hemos visto en la sesión anterior. \n",
    "Evalua y comenta los resultados obtenidos y comparalos con otros métodos de optimización de parámetros. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Ejemplo de una posible llamada:\n",
    "\n",
    "genetic_search = GeneticSearch(X, y, hyperparameter_space, model)\n",
    "genetic_search.search(generations=20, population_size=10, elite_rate=.1, selection_rate=.6, mutation_rate=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza los resultados en términos de calidad y tiempo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
